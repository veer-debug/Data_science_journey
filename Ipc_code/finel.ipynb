{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lemmatizer and stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords, convert to lowercase, lemmatize and remove duplicates\n",
    "    filtered_tokens = set()\n",
    "    for token in tokens:\n",
    "        token = token.lower()\n",
    "        if token.isalnum() and token not in stop_words:\n",
    "            lemmatized_token = lemmatizer.lemmatize(token)\n",
    "            filtered_tokens.add(lemmatized_token)\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['Discription'])\n",
    "y = df['Section']\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a classifier\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the classifier\n",
    "y_pred = classifier.predict(X)\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to recommend multiple sections based on input Discription in reverse order of probability\n",
    "def recommend_sections_reverse(Discription, n=2):\n",
    "    preprocessed_desc = preprocess_text(Discription)\n",
    "    desc_vectorized = vectorizer.transform([preprocessed_desc])\n",
    "    \n",
    "    # Predict probabilities for all classes\n",
    "    probas = classifier.predict_proba(desc_vectorized)\n",
    "    \n",
    "    # Get indices of top n probabilities in reverse order\n",
    "    top_n_indices = np.argsort(probas, axis=1)[:,-n:][:,::-1]\n",
    "    \n",
    "    # Get corresponding section names\n",
    "    top_n_sections = [classifier.classes_[idx] for idx in top_n_indices[0]]\n",
    "    \n",
    "    return top_n_sections\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the recommendation function\n",
    "Discription = \"I seek urgent assistance with a property dispute at [Address]. Despite legal attempts, unlawful occupation persists, disrupting our community. I urge prompt intervention to uphold the rightful owners' rights and restore order. Please contact me for further details. Thank you for your attention.\"\n",
    "# Discription='Abetment of any offence, if the act abetted is committed in consequence, and where no express provision is made for its punishment'\n",
    "\n",
    "recommended_sections_reverse = recommend_sections_reverse(Discription)\n",
    "print(\"Recommended Sections (Reverse Order):\", recommended_sections_reverse)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
